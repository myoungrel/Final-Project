from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from src.state import MagazineState
from src.config import config
from pydantic import BaseModel, Field
from langchain_core.output_parsers import PydanticOutputParser

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from src.state import MagazineState
from src.config import config
from pydantic import BaseModel, Field
from langchain_core.output_parsers import PydanticOutputParser
import re

# [ìˆ˜ì • 1] ì¶œë ¥ êµ¬ì¡°ì˜ ì„¤ëª…(Description)ì„ êµ¬ì²´í™”í•˜ì—¬ LLMì˜ íŒë‹¨ ê¸°ì¤€ ì™„í™”
class SafetyCheck(BaseModel):
    is_safe: bool = Field(description="ìœ í•´ì„± ì—¬ë¶€ (True: ì¡ì§€ ë°œí–‰, False: ë°œí–‰ ë¶ˆê°€)")
    reason: str = Field(description="íŒë‹¨ ì´ìœ . ì•ˆì „í•˜ë‹¤ë©´ 'Safe content' ë“±ìœ¼ë¡œ ê¸°ì¬.")
    pii_detected: list = Field(description="ì‹¤ì œ ê°œì¸ì •ë³´(ì£¼ë¯¼ë²ˆí˜¸, ê°œì¸ ì „í™”ë²ˆí˜¸ ë“±)ë§Œ í¬í•¨. ë¸Œëœë“œëª…ì´ë‚˜ ëª¨ë¸ëª…, ì´ë¦„ì€ ì œì™¸.")

def run_safety(state: MagazineState) -> dict:
    print("--- [2] Safety Filter: ë§¤ê±°ì§„ ì •ì±… ê¸°ë°˜ ê²€ìˆ˜ ì¤‘... ---")
    llm = config.get_llm()

    # 1. Pydantic Parser ì„¤ì •: LLMì´ JSON í˜•ì‹ì„ ì§€í‚¤ë„ë¡ ê°•ì œí•©ë‹ˆë‹¤.
    parser = PydanticOutputParser(pydantic_object=SafetyCheck)
    
<<<<<<< HEAD
    user_input = state.get("user_input", "") 
=======
    # [ìˆ˜ì • í›„] ì…ë ¥ê°’ íƒ€ì… ì•ˆì „ ì²˜ë¦¬
    raw_input = state.get("user_input") 

    # 1. Noneì´ê±°ë‚˜ ê°’ì´ ë¹„ì–´ìˆìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ë¡œ ì²˜ë¦¬
    if raw_input is None:
        user_input = ""
    # 2. ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš°(ë¦¬ìŠ¤íŠ¸, ê°ì²´ ë“±) ê°•ì œë¡œ ë¬¸ìì—´ë¡œ ë³€í™˜
    elif not isinstance(raw_input, str):
        user_input = str(raw_input)
    # 3. ì •ìƒ ë¬¸ìì—´ì¸ ê²½ìš°
    else:
        user_input = raw_input
>>>>>>> main

    # 2. ì •ê·œí‘œí˜„ì‹ì„ ì´ìš©í•œ ì‚¬ì „ PII ê²€ì‚¬ (Email, Phone ë“±)
    email_pattern = r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+'
    found_emails = re.findall(email_pattern, user_input)

    # [ìˆ˜ì • 2] í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§: í˜ë¥´ì†Œë‚˜ ë³€ê²½ ë° ì˜ˆì™¸ ìƒí™©(ë©´ì±…) ëª…ì‹œ
    # - í”„ë¡¬í”„íŠ¸ ìˆ˜ì •: ì¡ì§€ì‚¬ í¸ì§‘ì¥(Chief Editor) í˜ë¥´ì†Œë‚˜ ì ìš©
    # - ìƒì—…ì  ì •ë³´(ë¸Œëœë“œ, ì œí’ˆëª…)ëŠ” PIIê°€ ì•„ë‹˜ì„ ëª…ì‹œ
    prompt = ChatPromptTemplate.from_template(
        """
        You are the Chief Editor of a lifestyle magazine.
        Your goal is to approve content that is creative and engaging, while blocking illegal or harmful material.

        Analyze the text: "{user_input}"

        ### Guidelines for Approval:

        1. **PII (Personal Info):**
           - **ALLOW (Safe):** Names of public figures, interviewees, celebrities, brand names (e.g., Calvin Klein, Chanel), and models.
           - **BLOCK (Unsafe):** Private home addresses, SSNs, personal phone numbers, passwords.

        2. **Sexual Content:**
           - **ALLOW (Safe):** Fashion photography, artistic nudity, romance, swimsuit trends, or health-related topics.
           - **BLOCK (Unsafe):** Explicit pornography, non-consensual sexual content, or graphic sexual acts.

        3. **Hate & Violence (STRICT):**
           - **BLOCK (Unsafe):** Hate speech, promotion of terrorism, self-harm, or graphic violence.

        4. **Commercial Content:**
           - **ALLOW:** Product descriptions, prices, and marketing copies are 100% SAFE.

        {format_instructions}
        """
    ).partial(format_instructions=parser.get_format_instructions()) # Parserê°€ ìƒì„±í•œ ì§€ì¹¨ ì‚½ì…
    
    # 4. ì²´ì¸ êµ¬ì„± ë° í˜¸ì¶œ
    # ë³€ê²½ ì‚¬í•­: StrOutputParser() ëŒ€ì‹  ìœ„ì—ì„œ ì •ì˜í•œ parserë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    chain = prompt | llm | parser

    try:
        # resultëŠ” ì´ì œ SafetyCheck í´ë˜ìŠ¤ì˜ ì¸ìŠ¤í„´ìŠ¤(ê°ì²´)ê°€ ë©ë‹ˆë‹¤.
        result = chain.invoke({"user_input": user_input})
        
        # 5. ì •ê·œí‘œí˜„ì‹ ê²°ê³¼ì™€ LLM ê²°ê³¼ ë³‘í•©
        # ë³€ê²½ ì‚¬í•­: LLMì´ ë†“ì¹  ìˆ˜ ìˆëŠ” ì •ê·œì‹ íŒ¨í„´(ì´ë©”ì¼ ë“±)ì„ ìµœì¢… ê²°ê³¼ì— ê°•ì œë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.
        if found_emails:
            # ë‹¨, ì´ë©”ì¼ì´ íšŒì‚¬ ëŒ€í‘œ ë©”ì¼(ì˜ˆ: contact@samsung.com)ì¸ ê²½ìš° ë“±ì€ 
            # ì¶”í›„ ë¡œì§ì—ì„œ ì œì™¸í•  ìˆ˜ë„ ìˆìœ¼ë‚˜, ì¼ë‹¨ ì•ˆì „í•˜ê²Œ ì°¨ë‹¨ í˜¹ì€ ê²½ê³ ë¡œ ìœ ì§€
            result.is_safe = False
            result.pii_detected = list(set(result.pii_detected + found_emails))
            result.reason += " [System] Email pattern detected."

    except Exception as e:
        print(f"âŒ Safety Filter Error: {e}")
        # í´ë°± ì‹œì—ë„ ë„ˆë¬´ ê³µê²©ì ìœ¼ë¡œ ì°¨ë‹¨í•˜ì§€ ì•Šë„ë¡ ê¸°ë³¸ê°’ì„ ì¡°ì •í•  ìˆ˜ ìˆìœ¼ë‚˜,
        # ì‹œìŠ¤í…œ ì—ëŸ¬ ìƒí™©ì´ë¯€ë¡œ Falseë¡œ ë‘ëŠ” ê²ƒì´ ì•ˆì „í•¨.
        result = SafetyCheck(
            is_safe=False, 
            reason="Safety check failed due to system error. (Fallback activated)",
            pii_detected=[]
        )

    print(f"ğŸ›¡ï¸ ì•ˆì „ì„± ê²°ê³¼: {'SAFE' if result.is_safe else 'UNSAFE'} (ì‚¬ìœ : {result.reason})")

    # 6. ìµœì¢… State ë°˜í™˜
    # ë³€ê²½ ì‚¬í•­: Aê°€ ì •ì˜í•œ state êµ¬ì¡°ì— ë§ì¶° 'safety_check'ì™€ ìƒì„¸ 'safety_detail'ì„ í•¨ê»˜ ë„˜ê¹ë‹ˆë‹¤.
    return {
        "safety_check": "SAFE" if result.is_safe else "UNSAFE",
        "safety_detail": result.model_dump(), # ìƒì„¸ ë°ì´í„°(ì‚¬ìœ , PII ëª©ë¡) ì €ì¥ (Pydantic V2ë¶€í„°ëŠ” .dict() ëŒ€ì‹  .model_dump()ë¥¼ ì‚¬ìš©. dict ë¹—ê¸ˆë°œìƒ)
        "logs": [f"Safety: {result.is_safe}, Reason: {result.reason}"]
    }
