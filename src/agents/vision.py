import json
import os
import base64  # [Ï∂îÍ∞Ä]
import io      # [Ï∂îÍ∞Ä]
from PIL import Image
import google.generativeai as genai
from dotenv import load_dotenv

# 1. ÌôòÍ≤Ω Î≥ÄÏàò Î∞è Í≤ΩÎ°ú ÏÑ§Ï†ï
current_file_path = os.path.abspath(__file__)
tests_dir = os.path.dirname(current_file_path)
# .env ÌååÏùº ÏúÑÏπòÎäî ÌîÑÎ°úÏ†ùÌä∏ Íµ¨Ï°∞Ïóê ÎßûÍ≤å Ï°∞Ï†ïÌïòÏÑ∏Ïöî (Ïòà: ÏÉÅÏúÑ Ìè¥Îçî Îì±)
env_path = os.path.join(tests_dir, "..", "..", ".env") 
load_dotenv(dotenv_path=env_path)

# 2. API ÌÇ§ ÏÑ§Ï†ï
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    print("‚ùå [Vision] ÏóêÎü¨: GOOGLE_API_KEYÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. .env ÌååÏùºÏùÑ ÌôïÏù∏ÌïòÏÑ∏Ïöî.")
else:
    genai.configure(api_key=api_key)

def run_vision(state):
    print("--- [Vision Agent] Ïù¥ÎØ∏ÏßÄ Ï†ïÎ∞Ä Î∂ÑÏÑù ÏãúÏûë (Gemini) ---")
    
    # [New Code] Îã§Ï§ë Ïù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨ Î°úÏßÅ
    image_map = state.get("image_data", {}) # Dict[id, base64]
    user_inputs = state.get("user_input", []) # List[Dict]

    vision_results = {} # Í≤∞Í≥ºÎ•º Îã¥ÏùÑ Dict {id: result}

    # Î™®Îç∏ ÏÑ§Ï†ï (Gemini 1.5 Flash Í∂åÏû•, ÏóÜÏúºÎ©¥ Pro ÏÇ¨Ïö©)
    # user_textÏóê Ïñ∏Í∏âÎêú 2.5 Î™®Îç∏ÏùÄ ÏïÑÏßÅ Ï†ïÏãù ÏÇ¨Ïö©Ïù¥ Ïñ¥Î†§Ïö∏ Ïàò ÏûàÏñ¥ 1.5Î°ú ÏÑ§Ï†ïÌï©ÎãàÎã§.
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
    except:
        model = genai.GenerativeModel('gemini-2.5-flash')

    # Ïù¥ÎØ∏ÏßÄÍ∞Ä ÏóÜÏúºÎ©¥ Îπà Í≤∞Í≥º Î∞òÌôò
    if not image_map:
        print("‚ö†Ô∏è Î∂ÑÏÑùÌï† Ïù¥ÎØ∏ÏßÄÍ∞Ä ÏóÜÏäµÎãàÎã§.")
        return {"vision_result": {}}

    # Í∞Å Ïù¥ÎØ∏ÏßÄ Î≥ÑÎ°ú Î∞òÎ≥µ Î∂ÑÏÑù
    for article_id, b64_data in image_map.items():
        print(f"üì∏ Ïù¥ÎØ∏ÏßÄ Î∂ÑÏÑù Ï§ë... (ID: {article_id})")
        
        # Ìï¥Îãπ IDÏóê ÎßûÎäî ÏÇ¨Ïö©Ïûê ÌÖçÏä§Ìä∏ Ï∞æÍ∏∞ (ÌîÑÎ°¨ÌîÑÌä∏ Î∞òÏòÅÏö©)
        # user_inputs Î¶¨Ïä§Ìä∏ÏóêÏÑú idÍ∞Ä ÏùºÏπòÌïòÎäî Ìï≠Î™© Ï∞æÍ∏∞
        relevant_text = ""

        for item in user_inputs:
            if str(item.get("id")) == str(article_id):
                # requestÍ∞Ä ÏûàÏúºÎ©¥ Ïì∞Í≥† ÏóÜÏúºÎ©¥ titleÏù¥ÎùºÎèÑ ÏÇ¨Ïö©
                relevant_text = item.get("request") or item.get("title", "")
                break

        # üëá [ÏàòÏ†ïÎê®] ÏöîÏ≤≠ÌïòÏã† ÌîÑÎ°¨ÌîÑÌä∏Î•º ÏòÅÏñ¥Î°ú Î≤àÏó≠ÌïòÏó¨ Ï†ÅÏö©ÌñàÏäµÎãàÎã§.
        prompt = f"""
            You are the 'Chief Art Director'. 
            Request: "{relevant_text}"

            **[TASK: Step-by-Step Layout Decision]**
            Follow this exact order of thinking to decide "Overlay" vs "Separated".

            **STEP 1: Identify the 'HERO SUBJECT' (The Star)**
            - Find the Main Subject (Person, Watch, Bag).
            - **IGNORE** the background cleanliness for a moment. Focus ONLY on the Hero.

            **STEP 2: Analyze Hero's Dominance (The FATAL Check)**
            - **Is it a Person?** If yes, does the person occupy the **Center** of the image? -> If YES, STOP. Choose **'SEPARATED'**. (Never overlay text on a central portrait).
            - **Is it a Product?** Is it a "Macro Shot" (zoomed in extremely close)? -> If YES, STOP. Choose **'SEPARATED'**.
            - **Size Check:** Does the Hero Subject take up more than 50% of the image width/height? -> If YES, mostly **'SEPARATED'**.

            **STEP 3: Evaluate Background/Props (Only if Step 2 didn't stop you)**
            - Now look at the background.
            - **Case A (Prop as Canvas):** Is the Hero small, sitting on a huge uniform object (like a watch on a big white shell)? -> Choose **'OVERLAY'**.
            - **Case B (Clean Space):** Is the Hero off-center (Left/Right), leaving a huge empty sky/wall? -> Choose **'OVERLAY'**.

            **[Decision Logic Summary]**
            1. **Portrait/Central Human** = **SEPARATED** (Priority 1)
            2. **Zoomed-in Product** = **SEPARATED** (Priority 2)
            3. **Small Hero + Big Uniform Prop** = **OVERLAY** (Priority 3)
            4. **Small Hero + Clean Sky/Wall** = **OVERLAY** (Priority 4)

            **[JSON Data Structure]**
            1. thought_process: [Step-by-step reasoning based on the tasks above]
            2. layout_strategy:
                - recommendation: "Overlay" or "Separated"
                - reason: "Detailed reason for the choice"
            3. metadata: 
                - mood: "Visual mood keywords"
                - dominant_colors: ["#Hex1", "#Hex2", "#Hex3"]
                - lighting: "Lighting description"
                - dominant_position: "Left", "Right", or "Center"
                - design_guide: {{ "text_contrast": "Dark/Light", "font_recommendation": "Serif/Sans-serif" }}
                - composition_analysis: {{ "visual_weight": "...", "gaze_direction": "..." }}
                - texture_context: {{ "dominant_texture": "...", "seasonal_vibe": "..." }}
            4. safe_areas: [[ymin, xmin, ymax, xmax], ...] (Return [] if 'Separated')

            RETURN ONLY RAW JSON. NO MARKDOWN.

            **[JSON Response Example]**
            {{
                "thought_process": [
                    "Step 1: Hero is 'Watch'.",
                    "Step 2: Watch is on the right side, not central. Not a macro shot.",
                    "Step 3: Background is a large white seashell on the left.",
                    "Step 4: The seashell provides a clean, uniform 'canvas' for text.",
                    "Step 5: Decision 'Overlay' to utilize the negative space on the seashell."
                ],
                "layout_strategy": {{
                    "recommendation": "Overlay",
                    "reason": "The subject is off-center, and the uniform texture of the prop on the left provides an ideal surface for text overlay."
                }},
                "metadata": {{
                    "mood": "Oceanic, Luxury",
                    "dominant_colors": ["#F5F5F5", "#003366", "#111111"],
                    "lighting": "Soft studio light",
                    "dominant_position": "Right",
                    "design_guide": {{
                        "text_contrast": "Dark",
                        "font_recommendation": "Sans-serif"
                    }},
                    "composition_analysis": {{
                        "visual_weight": "Right-heavy (Watch)",
                        "gaze_direction": "Left"
                    }},
                    "texture_context": {{
                        "dominant_texture": "Smooth Shell Surface",
                        "seasonal_vibe": "Summer"
                    }}
                }},
                "safe_areas": [[100, 50, 800, 500]]
            }}

            RETURN ONLY RAW JSON. DO NOT USE MARKDOWN.
            """
        
        try:
            # [New Code]
            image_bytes = base64.b64decode(b64_data)
            # 2. BytesÎ•º Î©îÎ™®Î¶¨ ÌååÏùº(IO)Î°ú Î≥ÄÌôò ÌõÑ PILÎ°ú Ïó¥Í∏∞
            img = Image.open(io.BytesIO(image_bytes))
            
            # 3. GeminiÏóêÍ≤å Ï†ÑÏÜ°
            response = model.generate_content([prompt, img])
            
            # JSON Ï†ïÏ†ú
            json_res = response.text.replace("```json", "").replace("```", "").strip()

            # [New Code]
            vision_results[article_id] = json.loads(json_res)

        except Exception as e:
            print(f"‚ùå Vision Error (ID: {article_id}): {e}")
            # Ïã§Ìå® Ïãú Í∏∞Î≥∏Í∞í Ï†ÄÏû•
            vision_results[article_id] = {
                "layout_strategy": {"recommendation": "Separated"},
                "metadata": {"mood": "General"},
                "safe_areas": [],
                "dominant_colors": ["#FFFFFF", "#000000"]
            }

    return {"vision_result": vision_results}